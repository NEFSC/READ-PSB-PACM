---
title: "QAQC Moored and Glider Datasets"
author: "Jeffrey D Walker, PhD"
date: "8/3/2020"
output: 
  html_document: 
    toc: yes
    number_sections: yes
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(lubridate)
library(DT)
```

QAQC of moored and glider (v. 8/3/2020) data.

# Moored Dataset

## Metadata

### Load Files

```{r}
df_moored_meta_csv <- read_csv(
  "~/Dropbox/Work/nefsc/transfers/20200803 - mooring and glider data/Moored_metadata_2020-08-03.csv",
  col_types = cols(
    .default = col_character(),
    CHANNEL = col_integer(),
    LATITUDE = col_double(),
    LONGITUDE = col_double(),
    WATER_DEPTH_METERS = col_double(),
    RECORDER_DEPTH_METERS = col_double(),
    SAMPLING_RATE_HZ = col_double()
  )
) %>% 
  janitor::clean_names() %>% # cleans up column names, mainly convering to lowercase
  mutate(
    duty_cycle_seconds = tolower(duty_cycle_seconds) # normalizes Continuous and continuous
  ) %>% 
  select(unique_id, everything()) # bring unique_id to first column

df_moored_meta <- df_moored_meta_csv %>%
  mutate(
    submission_date = ymd(submission_date),
    monitoring_start_datetime = ymd_hms(monitoring_start_datetime),
    monitoring_end_datetime = ymd_hms(monitoring_end_datetime)
  )
```

### Dataset Summary

Summarize each data column to check for anomalies.

```{r}
# unique values
janitor::tabyl(df_moored_meta$platform_type)
janitor::tabyl(df_moored_meta$instrument_type)
janitor::tabyl(df_moored_meta$channel)
janitor::tabyl(df_moored_meta$soundfiles_timezone)
janitor::tabyl(df_moored_meta$duty_cycle_seconds)
janitor::tabyl(df_moored_meta$qc_data)

# timestamps
df_moored_meta %>% 
  select(where(is.Date)) %>%
  table()
df_moored_meta %>% 
  select(where(is.POSIXct)) %>%
  summary()

# numeric values
df_moored_meta %>% 
  select(where(is.numeric)) %>%
  summary()
```


```{r}
df_moored_meta_by_species <- df_moored_meta %>%
  rename_with(
    ~ str_replace(., "_", ":"),
    starts_with(c("narw_", "humpback_", "sei_", "fin_", "blue_"))
  ) %>% 
  pivot_longer(
    starts_with(c("narw", "humpback", "sei", "fin", "blue")),
    names_to = c("species", ".value"),
    names_sep = ":"
  ) %>% 
  select(unique_id, species, detection_method, protocol_reference)
```

`detection_method` is primarily LFDCS. NARW has 10 `Gillespie edge detector` rows, Humpback has 7 `Manual` rows, and all but blue has 5 `near real-time LFDCS`. Note that 1,560 rows are missing detection method presumably since they were not analyzed for that species.

```{r}
df_moored_meta_by_species %>% 
  janitor::tabyl(detection_method, species) %>% 
  janitor::adorn_totals(where = c("col", "row"))
```

`protocol_reference` is tied to `detection_method`. Note two different options for `LFDCS`.

```{r}
df_moored_meta_by_species %>% 
  filter(!is.na(detection_method)) %>% 
  janitor::tabyl(protocol_reference, detection_method)
```


### QAQC

#### Duplicate Project IDs

The `unique_id` column must contain only unique values in order to join `detections` table.

There is one pair of rows with the same `unique_id = NEFSC_SBNMS_200601_6`. Gen said this was an older recorder that does not have any detection results anyway, and thus will not be used in the web application.

```{r}
df_moored_meta %>%
  group_by(unique_id) %>% 
  add_count() %>% 
  filter(n > 1) %>% 
  arrange(project) %>% 
  select(-n) %>% 
  datatable()
```

#### Missing/Invalid Monitoring Period Timestamps

Each row should contain a monitoring start and end timestamps in ISO format (`YYYY-MM-DD HH:mm:ss`).

There are 3 projects missing both timestamps.

```{r}
df_moored_meta_csv %>%
  filter(is.na(monitoring_start_datetime) | is.na(monitoring_end_datetime)) %>% 
  datatable()
```

There are 17 projects in which the start/end timestamp is in the wrong format (`MM/DD/YY HH:mm` instead of `YYYY-MM-DD HH:mm:ss`). Ten of these are the Cornell Autobuoys, and the rest are from Mark Baumgartner. These need to be converted to ISO format.

```{r}
df_moored_meta_csv %>%
  filter(!is.na(monitoring_start_datetime), is.na(ymd_hms(monitoring_start_datetime)) | is.na(ymd_hms(monitoring_end_datetime))) %>% 
  datatable()
```


#### Missing Latitude/Longitude.

Each mooring/buoy must contain a latitude and longitude.

There are 4 projects with missing latitude and longitude.

```{r}
df_moored_meta %>% 
  filter(is.na(latitude) | is.na(longitude)) %>% 
  datatable()
```

## Detections

### Load Dataset

```{r}
df_moored_detect_csv <- read_csv(
  "~/Dropbox/Work/nefsc/transfers/20200803 - mooring and glider data/Moored_detection_data_2020-08-03.csv",
  col_types = cols(
    .default = col_character(),
    ANALYSIS_PERIOD_EFFORT_SECONDS = col_double(),
    NARW_N_VALIDATED_DETECTIONS = col_integer()
  )
) %>% 
  janitor::clean_names()

df_moored_detect <- df_moored_detect_csv %>% 
  mutate(
    analysis_period_start_datetime = ymd_hms(analysis_period_start_datetime),
    analysis_period_end_datetime = ymd_hms(analysis_period_end_datetime)
  )
```

### Dataset Summary

For this summary, convert to long format so that each species has its own row.

```{r}
df_moored_detect_by_species <- df_moored_detect %>%
  rename_with(
    ~ str_replace(., "_", ":"),
    starts_with(c("narw_", "humpback_", "sei_", "fin_", "blue_"))
  ) %>% 
  pivot_longer(
    starts_with(c("narw", "humpback", "sei", "fin", "blue")),
    names_to = c("species", ".value"),
    names_sep = ":"
  )
head(df_moored_detect_by_species)
```

Presence column should contain three unique values (`Detected`, `Not Detected`, `Possibly Detected`) across all species, but two additional and invalid values were found (`detected`, and `undetected`).

```{r}
df_moored_detect_by_species %>% 
  janitor::tabyl(presence, species)
```

Only NARW has `n_validated_detections`.

```{r}
df_moored_detect_by_species%>% 
  janitor::tabyl(n_validated_detections, species)
```

`call_type` varies by species.

```{r}
df_moored_detect_by_species%>% 
  janitor::tabyl(call_type, species)
```

### QAQC

#### Projects Do Not Exist in Both Tables

Some rows (projects) in the metadata table do not have corresponding values in the detections table based on the `unique_id` column. These are ok to leave in, but will not be shown on the web application.

There are `r sum(!df_moored_meta$unique_id %in% unique(df_moored_detect$unique_id))` rows from the metadata table do not have any matching rows in the detections table (value of `unique_id` not found).

```{r}
df_moored_meta %>% 
  filter(!unique_id %in% unique(df_moored_detect$unique_id)) %>% 
  datatable()
```

All rows in the detections table, however, do have matching rows in the metadata table.

```{r}
all(unique(df_moored_detect$unique_id) %in% unique(df_moored_meta$unique_id))
```

#### Invalid Presence Values

The presence columns must contain one of three unique and cap-sensitive values (`Detected`, `Not Detected`, `Possibly Detected`)

The Cornell Autobuoys contain invalid values (`detected`, `undetected`) for NARW presence:

```{r}
df_moored_detect_by_species %>% 
  filter(presence %in% c("detected", "undetected")) %>% 
  distinct(unique_id) %>% 
  datatable()
```


#### Non-Daily Detection Intervals

The moored detection data should be aggregated to daily timesteps since the map will ultimate show detection-days, which is a sum of daily values.

There are no projects with non-daily timesteps:

```{r}
unique_id_non_daily <- df_moored_detect %>% 
  filter(analysis_period_effort_seconds != 86400) %>% 
  pull(unique_id) %>% 
  unique()
df_moored_meta %>% 
  filter(unique_id %in% unique_id_non_daily) %>% 
  datatable()
```


# Glider Dataset

## Metadata

### Load Files

```{r}
df_glider_meta_csv <- read_csv(
  "~/Dropbox/Work/nefsc/transfers/20200803 - mooring and glider data/Glider_metadata_2020-08-03.csv",
  col_types = cols(
    .default = col_character(),
    CHANNEL = col_integer(),
    WATER_DEPTH_METERS = col_double(),
    RECORDER_DEPTH_METERS = col_double(),
    SAMPLING_RATE_HZ = col_double()
  )
) %>% 
  janitor::clean_names()

df_glider_meta <- df_glider_meta_csv %>% 
  mutate(
    submission_date = ymd(submission_date),
    monitoring_start_datetime = mdy_hm(monitoring_start_datetime), # NOTE: no longer in ISO
    monitoring_end_datetime = mdy_hm(monitoring_end_datetime)
  )
```

### Dataset Summary

Summarize each data column to check for anomalies.

```{r}
# unique values
janitor::tabyl(df_glider_meta$platform_type)
janitor::tabyl(df_glider_meta$instrument_type)
janitor::tabyl(df_glider_meta$channel)
janitor::tabyl(df_glider_meta$soundfiles_timezone)
janitor::tabyl(df_glider_meta$duty_cycle_seconds)
janitor::tabyl(df_glider_meta$qc_data)

# timestamps
df_glider_meta %>% 
  select(where(is.Date)) %>%
  table()
df_glider_meta %>% 
  select(where(is.POSIXct)) %>%
  summary()

# numeric values
df_glider_meta %>% 
  select(where(is.numeric)) %>%
  summary()
```

Note that glider metadata do not have `water_depth_meters` or `recorder_depth_meters`.


```{r}
df_glider_meta_by_species <- df_glider_meta %>%
  rename_with(
    ~ str_replace(., "_", ":"),
    starts_with(c("narw_", "humpback_", "sei_", "fin_", "blue_"))
  ) %>% 
  pivot_longer(
    starts_with(c("narw", "humpback", "sei", "fin", "blue")),
    names_to = c("species", ".value"),
    names_sep = ":"
  ) %>% 
  select(unique_id, species, detection_method, protocol_reference)
```

`detection_method` is always `near real-time LFDCS`. Note that 11 rows are missing detection method for each species, presumably since they were not analyzed for that species.

```{r}
df_glider_meta_by_species %>% 
  janitor::tabyl(detection_method, species) %>% 
  janitor::adorn_totals(where = c("col", "row"))
```

`protocol_reference` is tied directly to `detection_method`.

```{r}
df_glider_meta_by_species %>% 
  filter(!is.na(detection_method)) %>% 
  janitor::tabyl(protocol_reference, detection_method)
```


### QAQC


#### Missing/Invalid Monitoring Period Timestamps

Each row should contain a monitoring start and end timestamps in ISO format (`YYYY-MM-DD HH:mm:ss`).

There are 2 projects missing both timestamps.

```{r}
df_glider_meta_csv %>%
  filter(is.na(monitoring_start_datetime) | is.na(monitoring_end_datetime)) %>% 
  datatable()
```

The rest all use non-ISO format (`MM/DD/YY HH:mm`), and should be changed to ISO format. Here are the first few rows for example:

```{r}
df_glider_meta_csv %>% 
  select(project, monitoring_start_datetime, monitoring_end_datetime) %>% 
  head()
```


## Detections

### Load Files

```{r}
df_glider_detect_csv <- read_csv(
  "~/Dropbox/Work/nefsc/transfers/20200803 - mooring and glider data/Glider_detection_data_2020-08-03.csv",
    col_types = cols(
    .default = col_character(),
    ANALYSIS_PERIOD_EFFORT_SECONDS = col_double(),
    # NARW_N_VALIDATED_DETECTIONS = col_integer(), # Dropped?
    LATITUDE = col_double(),
    LONGITUDE = col_double()
  )
) %>% 
  janitor::clean_names() %>% 
  select(
    unique_id, analysis_period_effort_seconds, starts_with("analysis_period_"),
    latitude, longitude,
    starts_with("narw_"), starts_with("humpback_"), starts_with("sei_"), starts_with("fin_")
  )

df_glider_detect <- df_glider_detect_csv %>% 
  mutate(
    analysis_period_start_datetime = ymd_hms(analysis_period_start_datetime),
    analysis_period_end_datetime = ymd_hms(analysis_period_end_datetime)
  )
```

### Dataset Summary

For this summary, convert to long format so that each species has its own row.

```{r}
df_glider_detect_by_species <- df_glider_detect %>%
  rename_with(
    ~ str_replace(., "_", ":"),
    starts_with(c("narw_", "humpback_", "sei_", "fin_", "blue_"))
  ) %>% 
  pivot_longer(
    starts_with(c("narw", "humpback", "sei", "fin", "blue")),
    names_to = c("species", ".value"),
    names_sep = ":"
  )
head(df_glider_detect_by_species)
```

The glider detection dataset includes the `latitude` and `longitude` columns, which are part of the metadata for the moored stations.

```{r}
df_glider_detect_by_species %>% 
  select(latitude, longitude) %>% 
  summary()
```

Presence column only has three unique values (`Detected`, `Not Detected`, `Possibly Detected`).

```{r}
df_glider_detect_by_species %>% 
  janitor::tabyl(presence, species)
```

None of the species have `n_validated_detections` (only NARW did for the moored dataset).

`call_type` defined for each species.

```{r}
df_glider_detect_by_species%>% 
  janitor::tabyl(call_type, species)
```

### QAQC

#### Missing Latitude/Longitude

Each row must have a valid latitude and longitude.

These rows are missing the latitude and/or longitude.

```{r}
df_glider_detect %>% 
  filter(is.na(latitude) | is.na(longitude)) %>% 
  datatable()
```

#### Missing Analysis Period Timestamps

Each row must have a pair of valid analysis period start and end timestamps in ISO format (`YYYY-MM-DD HH:mm:ss`)

There are `r nrow(filter(df_glider_detect, is.na(analysis_period_start_datetime) | is.na(analysis_period_end_datetime)))` rows missing the start and/or end datetime. Here are the first 100 of those rows:

```{r}
df_glider_detect %>% 
  filter(is.na(analysis_period_start_datetime) | is.na(analysis_period_end_datetime)) %>% 
  head(100) %>% 
  datatable()
```
